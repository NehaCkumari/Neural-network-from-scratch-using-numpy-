{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural network from scratch using numpy .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NehaCkumari/Neural-network-from-scratch-using-numpy-/blob/master/Neural_network_from_scratch_using_numpy_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5T_SrU4QzXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sddQEpH7Q3RJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Y->Actual_output\n",
        "#Y is not seeded \n",
        "Y = (np.random.random((3,1))>0.5)*1\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "#X->inputs having 4 features and 3 training sets\n",
        "X = np.random.random((3,4))\n",
        "\n",
        "\n",
        "#number of hidden layers=2,number of nodes in hidden layers=6\n",
        "training_set =3\n",
        "learning_rate =0.01\n",
        "training_epochs=100000\n",
        "no_hidden_layers =2\n",
        "nodes_hidden =6\n",
        "no_in =4\n",
        "no_out =1\n",
        "\n",
        "#weights and biases\n",
        "W1 = 2*np.random.random((no_in,nodes_hidden))-1\n",
        "W2 = 2*np.random.random((nodes_hidden,nodes_hidden))-1\n",
        "W3 = 2*np.random.random((nodes_hidden,no_out))-1\n",
        "b1=np.ones((training_set,nodes_hidden))\n",
        "b2=np.ones((training_set,nodes_hidden))\n",
        "b3=np.ones((training_set,no_out))\n",
        "\n",
        "\n",
        "#sigmoid function as an activation function\n",
        "def sigmoid(z):\n",
        "    return((1.0/(1.0+np.exp(-z))))\n",
        "#sigmoid derivative\n",
        "def sigmoid_derivative(a):\n",
        "    return(np.multiply(a,(1-a)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FrZJi4qQ9PH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "de69713f-d26a-4084-c054-df9d2f5816c1"
      },
      "source": [
        "for epoch in range(training_epochs):\n",
        "    #forward propagation----------------\n",
        "    #layer1, layer2, layer3 and layer4 as a0,a1,a2,a3\n",
        "    #z=weight*inputs+bias\n",
        "    \n",
        "    a0=X\n",
        "    z1=np.add((np.dot(a0,W1)),b1)\n",
        "    a1=sigmoid(z1)\n",
        "    \n",
        "    z2=np.add((np.dot(a1,W2)),b2)\n",
        "    a2=sigmoid(z2)\n",
        "    \n",
        "    z3=np.add((np.dot(a2,W3)),b3)\n",
        "    a3=sigmoid(z3)\n",
        "              \n",
        "              \n",
        "    #backpropagation--------------------------\n",
        "    \n",
        "    #error in output layer as y_pred - Y\n",
        "    #error in weights as dw(l+1)=(1/m)*(a(l).T*da(l+1))\n",
        "    #w += -learning_rate * dw\n",
        "    \n",
        "    da3=np.subtract(a3,Y)\n",
        "    dw3=np.divide((np.dot(a2.T,da3)),training_set)\n",
        "    db3=np.divide((np.sum(da3,axis=1,keepdims=True)),training_set)\n",
        "    W3+=-np.multiply(learning_rate,dw3)\n",
        "    \n",
        "    da2=np.multiply(np.dot(da3,W3.T),sigmoid_derivative(a2))\n",
        "    dw2=np.divide((np.dot(a1.T,da2)),training_set)\n",
        "    db2=np.divide((np.sum(da2,axis=1,keepdims=True)),training_set)\n",
        "    W2+=-np.multiply(learning_rate,dw2)  \n",
        "    \n",
        "    da1=np.multiply(np.dot(da2,W2.T),sigmoid_derivative(a1))\n",
        "    dw1=np.divide((np.dot(a0.T,da1)),training_set)\n",
        "    db1=np.divide((np.sum(da1,axis=1,keepdims=True)),training_set)\n",
        "    W1+=-np.multiply(learning_rate,dw1)\n",
        "    \n",
        "   \n",
        "\n",
        "print(\"y_pred : \",(a3>0.5)*1,'\\n')\n",
        "print(\"Actual_output : \",Y)\n",
        "   \n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_pred :  [[0]\n",
            " [0]\n",
            " [0]] \n",
            "\n",
            "Actual_output :  [[0]\n",
            " [0]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP3YL5hTXg3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}